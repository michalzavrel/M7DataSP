{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyJNsvSFac3K"
   },
   "source": [
    "# Train CNN Classifier on human_ocr_ensembl dataset\n",
    "\n",
    "The dataset comes from the [Genomic Benchmarks](https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks). Best reaults achieved are reported in these [tables](https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks/tree/main/experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from genomic_benchmarks.data_check import info\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset `human_enhancers_cohn` has 2 classes: negative, positive.\n",
      "\n",
      "All lengths of genomic intervals equals 500.\n",
      "\n",
      "Totally 27791 sequences have been found, 20843 for training and 6948 for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>10422</td>\n",
       "      <td>3474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>10421</td>\n",
       "      <td>3474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "negative  10422  3474\n",
       "positive  10421  3474"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info(\"human_enhancers_cohn\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"katarinagresova/Genomic_Benchmarks_human_enhancers_cohn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq': 'TGGTGGTACTTGTCAGGACTTGGAGCAGCAGGTGCAAGATTTAGTGGGTTGGTTTTAGAATATCTGCTTGGAAAGTGGAAAAACTCAATGGATCATCTAGACTTTGGAATTTATCTCCTTCCCCACTTCTCCACTCCCCCAACAACAACAACAACAACAATGACAACAAAAACACCTGGAATAAACAGGTCATACAACGAGGTAGTTGATAGAATAATGTACTTTCCTTTCAGGCACCCCTTGGAGGAGGCAGATTCTGCCCTTTAAGCTGAATCTGCCTTTCCTGCATTTCCTGAAACTCCTGCATTTCCTGAAATCTTCCTGTATTTTCCTGAAATTTCCTGCCATTCCTGAAACTTTAAGGTAACTGTGTCATTAAAGGAAGGAGAGAAGGGAAGTATTAGGACTGCAGATTTGGGGTGCATGATCAGCCTGGCTCTGAGCTTGCAGACTCCCAGAGTCAGGGAAGGGAGGAGCCACCAGCAACCTTGTGGCTTACT',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, max_length=500):\n",
    "    one_hot = torch.zeros((4, max_length), dtype=torch.float32)\n",
    "    \n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    for i, nucleotide in enumerate(sequence[:max_length]):\n",
    "        if nucleotide in mapping:\n",
    "            one_hot[mapping[nucleotide], i] = 1.0\n",
    "\n",
    "    return one_hot\n",
    "    \n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.dataset = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.dataset[idx]['seq']\n",
    "        label = self.dataset[idx]['label']\n",
    "        encoded_seq = one_hot_encode(seq)\n",
    "        return encoded_seq, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "ds = dataset[\"train\"].with_format(\"torch\")\n",
    "ds = DNADataset(ds)\n",
    "\n",
    "# test data\n",
    "test_ds = dataset[\"test\"].with_format(\"torch\")\n",
    "\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = len(ds) - train_size\n",
    "\n",
    "train_ds, val_ds = torch.utils.data.random_split(ds, [train_size, val_size])\n",
    "\n",
    "test_ds = DNADataset(test_ds)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN for binary classification of DNA sequences\n",
    "class DNAClassifierCNN(nn.Module):\n",
    "    def __init__(self, kernel_size=5, stride = 1):\n",
    "        super(DNAClassifierCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=kernel_size, stride=stride)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=stride)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "        self.relu = nn.LeakyReLU()        \n",
    "        self.fc1 = nn.Linear(self.count_flatten_size(), 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def count_flatten_size(self):\n",
    "        dummy_input = torch.zeros(1, 4, 500)\n",
    "        dummy_output = self.pool(self.conv2(self.pool(self.conv1((dummy_input)))))\n",
    "        return dummy_output.view(-1).size(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.reshape(x.size(0), -1)  # Flatten for fully connected layer\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        labels = labels.float().to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs.to(DEVICE))\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, labels = batch\n",
    "            labels = labels.float().to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs.to(DEVICE))\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = (outputs.squeeze() > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model training and evaluation after each epoch\n",
    "def evaluation_loop(model, epochs, lr):\n",
    "    \n",
    "    adam = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_model(model, train_loader, adam, criterion)\n",
    "        avg_loss, accuracy = evaluate_model(model, val_loader, criterion)\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_loss}, Accuracy: {accuracy}')\n",
    "    \n",
    "    avg_loss, accuracy = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "    print(f'Loss: {avg_loss}, Accuracy: {accuracy}\\n')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Validation Loss: 0.5987304778954455, Accuracy: 0.6699448308946989\n",
      "Epoch 2/5, Validation Loss: 0.6021936736034073, Accuracy: 0.6778603981770208\n",
      "Epoch 3/5, Validation Loss: 0.6239265936021586, Accuracy: 0.6685056368433677\n",
      "Epoch 4/5, Validation Loss: 0.6555210492993129, Accuracy: 0.6541136963300551\n",
      "Epoch 5/5, Validation Loss: 0.7609890835885783, Accuracy: 0.6114176061405613\n",
      "Loss: 0.7609890835885783, Accuracy: 0.6114176061405613\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6114176061405613"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNAClassifierCNN().to(DEVICE)\n",
    "evaluation_loop(model, epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam optimization\n",
    "\n",
    "Let's try to optimize the learning rate, number of training epochs and size of the convolution kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_acc=0\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float('learning_rate', 0.00001, 0.01)\n",
    "    epochs = trial.suggest_int('epochs', 5, 10)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 5)\n",
    "    stride = trial.suggest_int('stride', 1, 4)\n",
    "\n",
    "    print(f\"LR: {lr}, Epochs: {epochs}, Kernel size: {kernel_size}, Stride = {stride}\")\n",
    "\n",
    "    model = DNAClassifierCNN(kernel_size=kernel_size, stride=stride).to(DEVICE)\n",
    "    \n",
    "    acc = evaluation_loop(model, epochs, lr)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_model = model\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:04:53,831] A new study created in memory with name: no-name-f7022d2f-657a-4cd0-a253-8b84b39af3e3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0014032574889357408, Epochs: 5, Kernel size: 3, Stride = 1\n",
      "Epoch 1/5, Validation Loss: 0.5990545224142438, Accuracy: 0.6761813384504677\n",
      "Epoch 2/5, Validation Loss: 0.6117415412236716, Accuracy: 0.6627488606380427\n",
      "Epoch 3/5, Validation Loss: 0.5853131404359833, Accuracy: 0.6862556968097865\n",
      "Epoch 4/5, Validation Loss: 0.6132927491464688, Accuracy: 0.6735428160230271\n",
      "Epoch 5/5, Validation Loss: 0.6401779945115097, Accuracy: 0.6553130247061646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:09:03,146] Trial 0 finished with value: 0.6553130247061646 and parameters: {'learning_rate': 0.0014032574889357408, 'epochs': 5, 'kernel_size': 3, 'stride': 1}. Best is trial 0 with value: 0.6553130247061646.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6401779945115097, Accuracy: 0.6553130247061646\n",
      "\n",
      "LR: 0.003929721323855199, Epochs: 7, Kernel size: 3, Stride = 1\n",
      "Epoch 1/7, Validation Loss: 0.5959113554190133, Accuracy: 0.6860158311345647\n",
      "Epoch 2/7, Validation Loss: 0.594130270581209, Accuracy: 0.681458383305349\n",
      "Epoch 3/7, Validation Loss: 0.6087743146273926, Accuracy: 0.6713840249460302\n",
      "Epoch 4/7, Validation Loss: 0.6252218964900679, Accuracy: 0.6687455025185896\n",
      "Epoch 5/7, Validation Loss: 0.7207625132935648, Accuracy: 0.6584312784840489\n",
      "Epoch 6/7, Validation Loss: 0.8728863951814083, Accuracy: 0.637083233389302\n",
      "Epoch 7/7, Validation Loss: 1.4222625789751533, Accuracy: 0.6442792036459583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:14:49,245] Trial 1 finished with value: 0.6442792036459583 and parameters: {'learning_rate': 0.003929721323855199, 'epochs': 7, 'kernel_size': 3, 'stride': 1}. Best is trial 0 with value: 0.6553130247061646.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4222625789751533, Accuracy: 0.6442792036459583\n",
      "\n",
      "LR: 0.0071867061549229574, Epochs: 8, Kernel size: 3, Stride = 1\n",
      "Epoch 1/8, Validation Loss: 0.6931520436556284, Accuracy: 0.502038858239386\n",
      "Epoch 2/8, Validation Loss: 0.693392931505014, Accuracy: 0.49796114176061407\n",
      "Epoch 3/8, Validation Loss: 0.6931588440451003, Accuracy: 0.502038858239386\n",
      "Epoch 4/8, Validation Loss: 0.6933377394239411, Accuracy: 0.49796114176061407\n",
      "Epoch 5/8, Validation Loss: 0.6938707182425579, Accuracy: 0.502038858239386\n",
      "Epoch 6/8, Validation Loss: 0.6931698335946062, Accuracy: 0.502038858239386\n",
      "Epoch 7/8, Validation Loss: 0.6933367557198037, Accuracy: 0.502038858239386\n",
      "Epoch 8/8, Validation Loss: 0.6931500407575651, Accuracy: 0.49796114176061407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:21:21,846] Trial 2 finished with value: 0.49796114176061407 and parameters: {'learning_rate': 0.0071867061549229574, 'epochs': 8, 'kernel_size': 3, 'stride': 1}. Best is trial 0 with value: 0.6553130247061646.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6931500407575651, Accuracy: 0.49796114176061407\n",
      "\n",
      "LR: 0.008066449792986534, Epochs: 8, Kernel size: 3, Stride = 2\n",
      "Epoch 1/8, Validation Loss: 0.6209878284512586, Accuracy: 0.6442792036459583\n",
      "Epoch 2/8, Validation Loss: 0.6026420620561556, Accuracy: 0.660110338210602\n",
      "Epoch 3/8, Validation Loss: 0.6022365022706622, Accuracy: 0.673782681698249\n",
      "Epoch 4/8, Validation Loss: 0.6115119291170863, Accuracy: 0.6521947709282802\n",
      "Epoch 6/8, Validation Loss: 0.6031349078389524, Accuracy: 0.681458383305349\n",
      "Epoch 7/8, Validation Loss: 0.5968186272919633, Accuracy: 0.6826577116814584\n",
      "Epoch 8/8, Validation Loss: 0.5880206056678569, Accuracy: 0.6800191892540177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:27:54,114] Trial 3 finished with value: 0.6800191892540177 and parameters: {'learning_rate': 0.008066449792986534, 'epochs': 8, 'kernel_size': 3, 'stride': 2}. Best is trial 3 with value: 0.6800191892540177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5880206056678569, Accuracy: 0.6800191892540177\n",
      "\n",
      "LR: 0.007786720650814143, Epochs: 9, Kernel size: 5, Stride = 2\n",
      "Epoch 1/9, Validation Loss: 0.5956250106105367, Accuracy: 0.6766610698009115\n",
      "Epoch 2/9, Validation Loss: 0.5839012494979013, Accuracy: 0.6886543535620053\n",
      "Epoch 3/9, Validation Loss: 0.604105435027421, Accuracy: 0.6797793235787959\n",
      "Epoch 4/9, Validation Loss: 0.5918430799746331, Accuracy: 0.6888942192372272\n",
      "Epoch 5/9, Validation Loss: 0.5641004827641348, Accuracy: 0.7100023986567522\n",
      "Epoch 6/9, Validation Loss: 0.5844512979947883, Accuracy: 0.6831374430319022\n",
      "Epoch 7/9, Validation Loss: 0.5670674966491815, Accuracy: 0.7006476373230991\n",
      "Epoch 8/9, Validation Loss: 0.5871302228392535, Accuracy: 0.6857759654593427\n",
      "Epoch 9/9, Validation Loss: 0.5743113435406721, Accuracy: 0.6956104581434397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-23 13:35:15,148] Trial 4 finished with value: 0.6956104581434397 and parameters: {'learning_rate': 0.007786720650814143, 'epochs': 9, 'kernel_size': 5, 'stride': 2}. Best is trial 4 with value: 0.6956104581434397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5743113435406721, Accuracy: 0.6956104581434397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.007786720650814143, 'epochs': 9, 'kernel_size': 5, 'stride': 2}\n",
      "Best value (validation AU PRC): 0.6956104581434397\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyperparameters: {study.best_params}\")\n",
    "print(f\"Best value (validation AU PRC): {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6932481705048762\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "best_model = DNAClassifierCNN(kernel_size=best_params['kernel_size'], stride=best_params['stride']).to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(best_params['epochs']):\n",
    "    train_model(best_model, train_loader, optimizer, criterion)\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model(best_model, test_loader, criterion)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "interpreter": {
   "hash": "af167c304fdc99884e31a029277e630a5b00036f91292350fffdeed1d15b16ff"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
